THIS WE NEED TO DO!!!!! 

20130930, Extras
  - Context: explain that this can be used to provide highlighting in an editor such as Yi (see reference below); 
  and that the current incremental parsing algorithm (see ref. below) is brittle.
@inproceedings{bernardy_editor_2008,
	author = {Jean-Philippe Bernardy},
	address = {Victoria, {BC,} Canada},
	title = {Yi: an editor in {{Haskell}} for {{Haskell}}},
	isbn = {978-1-60558-064-7},
	shorttitle = {Yi},
	url = {http://portal.acm.org/citation.cfm?id=1411286.1411294},
	doi = {10.1145/1411286.1411294},
	abstract = {Yi is a text editor written in Haskell and extensible in Haskell. 
	We take advantage of Haskell's expressive power to define embedded {DSLs} that f
	orm the foundation of the editor. In turn, these {DSLs} provide a flexible mechanism t
	o create extended versions of the editor. Yi also provides some support for editing Haskell code.},
	booktitle = {Proceedings of the first {ACM} {SIGPLAN} symposium on Haskell},
	publisher = {{ACM}},
	year = {2008},
	keywords = {editor, functional programming},
	pages = {61--62}
},
@inproceedings{bernardy_lazy_2009,
	author = {Jean-Philippe Bernardy},
	address = {Edinburgh, Scotland},
	title = {Lazy functional incremental parsing},
	isbn = {978-1-60558-508-6},
	url = {http://portal.acm.org/citation.cfm?id=1596638.1596645},
	doi = {10.1145/1596638.1596645},
	abstract = {Structured documents are commonly edited using a free-form editor. 
	Even though every string is an acceptable input, it makes sense to maintain a structured 
	representation of the edited document. The structured representation has a number of 
	uses: structural navigation (and optional structural editing), structure highlighting, 
	etc. The construction of the structure must be done incrementally to be efficient: the 
	time to process an edit operation should be proportional to the size of the change, 
	and (ideally) independent of the total size of the document. We show that combining lazy 
	evaluation and caching of intermediate (partial) results enables incremental parsing.
	We build a complete incremental parsing library for interactive systems with support 
	for error-correction.},
	booktitle = {Proceedings of the 2nd {ACM} {SIGPLAN} symposium on Haskell},
	publisher = {{ACM}},
	year = {2009},
	keywords = {dynamic programming, editor, haskell, incremental computing, lazy evaluation, parsing, polish representation},
	pages = {49--60},
	see = {cites:wagner_efficient_1998;cites:ghezzi_incremental_1979}
},

20130930:
- For performance testing: take the measure of the final tree, and just do whnf of that.
- Report:
  - Explain what the parameter (e) means on 
      1. e=1 the mergesort example (every node must be visited once) 
      2. e=0 the incremental case  (only log(n) nodes are visited, the cost of visiting one node 
      will dominate the running time)
  x The testing section should be folded into results (explain every result after how you measure it)
  x Sort your references by author last name (sort option to the package)
  - Cite me :) 
  x The reference for Data.Sequence is Hinze and Patersson (Finger Trees)
  x Rename sec. 4 to "implementation"
  Read and Rewrite:
  	1.opening - Add more candy to the store
  	1.1 - Add more candy to the store
  	1.2 - This text feels lite the writer was in need of taking a poo while writing.
  
  	2.1 - Saing same thing several times
  	2.2.1 - No harmoni in the text
  	2.2.3 - Check sentances.
  	2.3.opening - Check sentances
  	2.3.token remove last sentence
  	2.4.2 - Remove, description of regualr expression
  	
  	

@article{hinze_finger_2006,
	author = {Ralf Hinze and Ross Paterson},
	title = {Finger trees: a simple general-purpose data structure},
	journal = {Journal of Functional Programming},
	volume = {16},
	number = {2},
	pages = {197--218},
	year = {2006},
	publisher = {Cambridge Univ Press}
},

@inproceedings{bernardy_efficient_2013,
	author = {Jean-Philippe Bernardy and Koen Claessen},
	title = {Efficient Divide-and-Conquer Parsing of Practical Context-Free Languages},
	year = {2013},
	booktitle = {Proceeding of the 18th {ACM} {SIGPLAN} international conference on Functional Programming},
	note = {To appear}
}, 

20130923:
- Try to replace String by sequence of chars
- Try to estimate how much "ambiguity" there is in the tree.
  

20130916:

report:
- add a section on divide and conquer in general (see Master theorem)
- section on divide and conquer lexing in general (composition of DFA)
- our problem: longest match
- references: Introduction to automata theory ...  from Hopcroft, Motwani and Ullman
              MapReduce

write a quickcheck property which:
- starts with a given known correct input string
- selects a random substring; splits it in two parts (l,r)
- run the lexer on l and r separately
- merges the resuts
- tests that there is at least one possible result in the final output

BONUS: 
 - write a shrinker to find smallest cases automatically


"plot" the (incremental) lexing time against the size of the file

20130821:

Current solution:

Transition = State -> (Prefix,Seq Tokens,Suffix)
Suffix = Either State -- This is an accepting states
                ((PartialToken,State),(Sequence of 'unsure,small' tokens,PartialToken,State))

- Test for full correctness:
  * take a valid input
  * split it in all intermediate positions; and for each of those: --- Done and works
    * parse parts separately
    * combine
- Design proper incrementality test
  - Experiment tabulating the top-level function --- Done, updates faster for array, tree construction faster for functional composition
- Cleanup/Productize (as an alex template)
- Report:
  - Explain "most general" solution, without longest-matching rule
  - Compare the pros and cons. of various approaches. (including why some do not work at all)


20130814:

- Test some more with incremental updates
- Experiment tabulating the top-level function
- Cleanup/Productize (as an alex template)
- Report.

--LEXER STUFF--
General:
-Needs to ba able to handle special characters (UNASSIGNED)
-DFA needs to know accepting states. (Done, Maybe implement the priority structure?)
-Implement good error messages (UNASSIGNED)
-Implement test cases for our lexer (UNASSIGNED)
-Stupid bug when certain stuff are inserted which result in no tokens being generated for example "/**/"

HsBuilder.hs:
-Datastructure for DFA (KoffKoff, Better datatstructure for the inner map?)
-Better conversion from DFA then currently implemented (UNASSIGNED)
-How do we handle errors? example ("blablabla \n)
-Can we strip som of the transitions??

Main.hs
-Needed for anything but bug testing?

IncLex.hs:
-Check for more bugs (UNASSIGNED)
-Can we strip som of the transitions??

AbsSyn.hs
-Maybe move more data strucures here?

Alex:
-Remove as much as possible (UNASSIGNED)
    -Remove not needed files (HUGO)
    -Remove not needed code (UNASSIGNED)

BuildDFA.hs
-Is it done?

--REPORT STUFF--
Chpater 2:
-Find more ref. and fill out the text (UNASSIGNED)

Chapter 3:
-Write an introduction part (KoffKoff)
-Start by make a list of what would be written about. (UNASSIGNED)
-Formal proof that our combination yields the correct token. (UNASSIGNED)
