THIS WE NEED TO DO!!!!!


20130930:
- For performance testing: take the measure of the final tree, and just do whnf of that.
- Report:
  - Explain what the parameter (e) means on 
      1. e=1 the mergesort example (every node must be visited once) 
      2. e=0 the incremental case  (only log(n) nodes are visited, the cost of visiting one node will dominate the running time)
  x The testing section should be folded into results (explain every result after how you measure it)
  x Sort your references by author last name (sort option to the package)
  - Cite me :) 
  x The reference for Data.Sequence is Hinze and Patersson (Finger Trees)
  x Rename sec. 4 to "implementation"

@article{hinze_finger_2006,
	author = {Ralf Hinze and Ross Paterson},
	title = {Finger trees: a simple general-purpose data structure},
	journal = {Journal of Functional Programming},
	volume = {16},
	number = {2},
	pages = {197--218},
	year = {2006},
	publisher = {Cambridge Univ Press}
},

@inproceedings{bernardy_efficient_2013,
	author = {Jean-Philippe Bernardy and Koen Claessen},
	title = {Efficient Divide-and-Conquer Parsing of Practical Context-Free Languages},
	year = {2013},
	booktitle = {Proceeding of the 18th {ACM} {SIGPLAN} international conference on Functional Programming},
	note = {To appear}
}, 

20130923:
- Try to replace String by sequence of chars
- Try to estimate how much "ambiguity" there is in the tree.
  

20130916:

report:
- add a section on divide and conquer in general (see Master theorem)
- section on divide and conquer lexing in general (composition of DFA)
- our problem: longest match
- references: Introduction to automata theory ...  from Hopcroft, Motwani and Ullman
              MapReduce

write a quickcheck property which:
- starts with a given known correct input string
- selects a random substring; splits it in two parts (l,r)
- run the lexer on l and r separately
- merges the resuts
- tests that there is at least one possible result in the final output

BONUS: 
 - write a shrinker to find smallest cases automatically


"plot" the (incremental) lexing time against the size of the file

20130821:

Current solution:

Transition = State -> (Prefix,Seq Tokens,Suffix)
Suffix = Either State -- This is an accepting states
                ((PartialToken,State),(Sequence of 'unsure,small' tokens,PartialToken,State))

- Test for full correctness:
  * take a valid input
  * split it in all intermediate positions; and for each of those: --- Done and works
    * parse parts separately
    * combine
- Design proper incrementality test
  - Experiment tabulating the top-level function --- Done, updates faster for array, tree construction faster for functional composition
- Cleanup/Productize (as an alex template)
- Report:
  - Explain "most general" solution, without longest-matching rule
  - Compare the pros and cons. of various approaches. (including why some do not work at all)


20130814:

- Test some more with incremental updates
- Experiment tabulating the top-level function
- Cleanup/Productize (as an alex template)
- Report.

--LEXER STUFF--
General:
-Needs to ba able to handle special characters (UNASSIGNED)
-DFA needs to know accepting states. (Done, Maybe implement the priority structure?)
-Implement good error messages (UNASSIGNED)
-Implement test cases for our lexer (UNASSIGNED)
-Stupid bug when certain stuff are inserted which result in no tokens being generated for example "/**/"

HsBuilder.hs:
-Datastructure for DFA (KoffKoff, Better datatstructure for the inner map?)
-Better conversion from DFA then currently implemented (UNASSIGNED)
-How do we handle errors? example ("blablabla \n)
-Can we strip som of the transitions??

Main.hs
-Needed for anything but bug testing?

IncLex.hs:
-Check for more bugs (UNASSIGNED)
-Can we strip som of the transitions??

AbsSyn.hs
-Maybe move more data strucures here?

Alex:
-Remove as much as possible (UNASSIGNED)
    -Remove not needed files (HUGO)
    -Remove not needed code (UNASSIGNED)

BuildDFA.hs
-Is it done?

--REPORT STUFF--
Chpater 2:
-Find more ref. and fill out the text (UNASSIGNED)

Chapter 3:
-Write an introduction part (KoffKoff)
-Start by make a list of what would be written about. (UNASSIGNED)
-Formal proof that our combination yields the correct token. (UNASSIGNED)
