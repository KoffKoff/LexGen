\chapter{Lexer}
A Lexer, lexical analyser, is a pattern matcher. It's job is to find sequence 
of characters in a larger string. The Lexer is a front end of a syntax 
analyser. \cite{sebesta2012}
This can be done by using regular expressions, regular sets and finite
automata. Which are central concepts in formal language theory. \cite{Aho1990}
All on which will be described in this chapter.

\section{Lexing vs Parsing}
There are several reasons why a compiler should be separated in to lexical 
analyser and a parser (syntax analyser) phases. Simplicity of design is the most
important reason. When dividing the task in to these to sub task, it allows the
system to simplify one of these sub-tasks. For example, a parser that has to 
deal with white-spaces and comments as syntactical units would be more complex 
then one that can assume white-spaces and comments have already been removed by 
an lexer. Also when the two tasks are divided into sub-tasks it can lead to 
cleaner overall design when designing a new language \cite{Aho2006}
Lexers work as a subprogram to the parser, giving it's result to the syntax 
analyser. So the only thing the syntax analyser will see is the output from the 
lexer, tokens and lexemes which will be described later in this chapter. 
\cite{sebesta2012}
The lexer also skips comments and white-spaces, since these are not relevant 
for the syntax analyser. \cite{sebesta2012}
Also overall efficiency of the compiler can be improved. When separating the 
lexical analyser it allows for appliance of specialised techniques that serve 
only the lexical task. \cite{Aho2006}
Last compiler portability can be enhanced. That is Input-device-specific 
peculiarities can be restricted to the lexical analysis. \cite{Aho2006}
So the lexer can detect syntactical errors in tokens, such as ill-formed 
floating-points literals, and report these errors to the user. 
\cite{sebesta2012} Breaking the compilation before running the syntax analyser, 
saving computing time. 

\section{Token Specification}
This section will describe how to write rules for the tokens patterns. 
\subsection{Languages}
An alphabet is an finite set of symbols, such an alphabet is for example the 
unicode, which includes approximately $100,000$ characters. A language is any 
countable set of strings over some fixed alphabet. \cite{Aho2006}

\#More text on languages!!!!

Like any formal language, a regular language is a set of strings. In other 
words a sequence of symbols,
from a finite set of symbols. Only some formal languages are regular; in fact, 
regular languages are exactly those that can be defined by regular expressions.
\cite{Ranta2012}
\subsection{Regular Expressions}
Say that we want to express the set of valid C identifiers. Use of regular 
expressions make it very easy, as shown in \cref{regexpEx}. 
\begin{example}[Valid C Idents]\label{regexpEx}
Say we have a element $letter \in \{$a$ \dots $z$\} \cup \{$A$ \dots $Z$\} \cup 
\{$\_$\}$
and another element $digit \in \{0 \dots 9\}$
Then with help of regular expressions the definition of all valid C identifiers 
would look like this: $letter (letter | digit)*$. \cite{Aho2006}
\end{example}
In \cref{regexp} is the formal definition for regular expressions.
\begin{definition}[Regular Expressions]\label{regexp} \cite{Aho1990}
\newline
\begin{enumerate}
  \item The following characters are meta characters $\{ '|', '(', ')', '*' \}$.
  \item A none meta character $a$ is a regular expression that matches the 
      string $a$.
  \item If $r_1$ and $r_2$ are regular expressions then $(r_1 | r_2)$ is a 
      regular expression that matches any string that matches $r_1$ or $r_2$.
  \item If $r_1$ and $r_2$ are regular expressions. $(r_1)(r_2)$ is a regular
      expression of the form that matches the string $xy$ iff $x$ matches $r_1$
      and $y$ matches $r_2$.
  \item If $r$ is a regular expression the $r*$ is a regular expression that
      matches any string of the form $x_1, x_2, \dots , x_n, n \geq 0$.
      Where $r$ matches $x_i$ for $1 \leq i \leq n$, in particular $(r)*$ 
      matches the empty string, $\varepsilon$.
  \item If $r$ is a regular expression, then $(r)$ is a regular expression that
      matches the same string as $r$.
\end{enumerate}
\end{definition}
Many parentheses can be reduced by adopting the convention that the Kleene
closure operator $*$ has the highest precedence, then concat and then or
operator $|$. The two binary operators, cancat and $|$ are left 
left-associative. \cite{Aho1990}
\subsection{Regular Definitions}
In a definition of a language it is useful to give regular expressions names, 
so they can for example be used in other regular expressions, as these names 
where themself symbols. If $\Sigma$ is an alphabet of basic symbols, then a 
regular definition is a sequence of definitions of the form:
\begin{center}
\begin{tabular}{l c r}
$d_1$ & $\to$ & $r_1$\\
$d_2$ & $\to$ & $r_2$\\
$\vdots$ & $\to$ & $\vdots$\\
$d_n$ & $\to$ & $r_n$\\

\end{tabular}
\end{center}
where:
\begin{enumerate}
\item Each $d_i$ is a new symbol, not in $\Sigma$ and not the same as any other 
of the $d$'s.
\item Each $r_i$ is a regular expression over the alphabet $\Sigma  \cup \{d_1, 
d_2 \dots d_{i-1}\}$
\end{enumerate}
By restricting $r_i$ to $\Sigma$ and previously defined $d$'s the regular 
definitions avoid recursive definitions.  
\cite{Aho2006}

\section{Tokens, Patterns and Lexemes}
A lexical analyser uses three different terms. All which is described here 
below. 
\begin{description}
  \item[Token]
    is a pair consisting of a token name and an optional attribute value. The 
token name is a abstract symbol corresponding to a lexical unit \cite{Aho2006}. 
For example, a particular keyword, datatype or identifier.  The token names is 
what is given to the parser. 
  \item[Pattern]
    is a description of what form a lexemes of a token may take. \cite{Aho2006} 
For example, a keyword is just the sequence of characters that forms the 
keyword, an int is just a sequence consisting of just numbers. 
  \item[Lexemes]
    is a sequence of characters in the code that is being analysed which 
matches the pattern for a token and is identified by the lexical analyser as an 
instance of a token. \cite{Aho2006}
\end{description}
As mention before a token consist of token name and a optional attribute value. 
This attribute is used when one lexeme can match more then one pattern. \cite
{Aho2006} For example the pattern for a digit token matches both $0$ and $1$, 
but it is important for the code generator to know which lexeme was found. 
Therefor the lexer often return not just the token but also an attribute value 
that describes the lexeme found in the source program corresponding to this 
token. \cite{Aho2006} A lexer collects chars into logical groups and assign 
internal codes to these groups. according to there structure.\cite{sebesta2012} 
Where the groups of chars are lexemes and the internal codes are tokens. Here 
follows a example how a small piece of code would be divided.
\begin{example}[Logical grouping] \label{codeToToken} \cite{sebesta2012} \\
This is the code being lexed:
\lstinputlisting[language=c]{examples/token.c}
This is how it will be divided:
\begin{center}
\begin{tabular}{l c}
\underline{Token} & \underline{Lexeme}\\
IDENT & result\\
ASSING\_OP & $=$\\
IDENT & oldsum\\
SUB\_OP & $-$\\
IDENT & value\\
DIV\_OP & $/$\\
INT\_LIT & 100\\
SEMICOLON & ;
\end{tabular}
\end{center}
\end{example}

\section{Recognition of Tokens}
In previous section the topic have been, how to represent a pattern using 
regular expressions and how these expressions relates to tokens. This section 
will highlight how to transform a sequence of characters into a sequence of 
abstract tokens. First some basic understanding with transition diagrams.  
\subsection{Transition Diagrams}
A state transition diagram, or just transition diagram is a directed graph. 
Where the nodes are labelled with the state name. Each node 
represent a state which could occur during the process of scanning the input 
looking for lexeme that matches one of several patterns.\cite{Aho2006} The 
edges are labelled with the input characters that causes the transition among 
the states. An edge may also contain actions the lexer must perform when 
transition is token.\cite{sebesta2012} Here follows some properties for a 
transition diagram, One state is said to be initial state. The transition 
diagram always begins at this state, before any input symbols have been read. 
Some states are said to be accepting (final). They indicate that a lexeme has 
been found. The found token should then be returned with any additional 
optional values, mentioned in previous section.\cite{Aho2006}
Transition diagrams of the formed used in lexers are representations of a class 
of mathematical machines called finite automata. Finite automata can be 
designed to recognise members of a class of languages called regular languages, 
mentioned above \#write about this shit in previus sections!!!! \#.
\cite{sebesta2012} 
\subsection{Finite Automata}
A finite automata are essentially graphs, like transitions diagrams, with some 
differences:
\begin{itemize}
  \item Finite automata are recognizers; they simply say "YES" or "NO" about 
each possible input string.
  \item Finite automata comes in to different forms:
    \begin{description}
      \item [Nondeterministic Finite Automata (NFA)] which have no restriction 
of the edges, several edges can be labelled by the same symbol out from the 
same state. $\epsilon$, the empty string, is a possible label. 
      \item [Deterministic Finite Automata (DFA)] for each state and for each 
symbol of its input alphabet exactly one edge with that symbol leaving that 
state
    \end{description}
\end{itemize}
Both these forms of finite automate are capable of recognising the same 
language, called regular languages. These are languages that regular 
expressions can describe. \cite{Aho2006}
The formal definition of a finite automata follows:
\begin{definition}[Finite Automata] \label{finiteAutomataDef} 
\cite{sipser2006} \\
A finite automata is a 5-tuple $(Q, \Sigma, \delta, q_0, F)$, where
\begin{enumerate}
  \item $Q$ is a finite set called the states,
  \item $\Sigma$ is a finite set called alphabet,
  \item $\delta: Q \times \Sigma \to Q$ is a transition function,
  \item $q_0 \in Q$ is the start state, and
  \item $F \subseteq Q$ is the set of accept states.
\end{enumerate}

\end{definition}
\subsubsection{Nondeterministic Finite Automata}
An NFA accept input $x$ if and only if there is a path in the transition diagram from the start state to one of the accepting states. Such that the symbols along the way spells out $x$. \cite{Aho2006}

There are different ways of representing an NFA, one is by transition diagrams another is by transitions table. This example shows how a regular expression can be converted in to a transition diagram.
\newpage
\begin{example}[RegExp to Transition Diagram] \label{regexp2td}
\cite{Aho2006}\\
Given this regular expression: $(a | b)* abb$ \\
the transition diagram representing this regular expression is shown the figure below.
\begin{figure}[h!]
  \centering
  \begin{tikzpicture}[
    % Default arrow tip
    ->,>=stealth',shorten >=1pt,auto,
    % Default node distance
    node distance=2cm,
    % Edge stroke thickness: semithick, thick, thin
    semithick
    ]

    \newState{0}{$0$}{initial}{}
    \newState{1}{$1$}{right of=0}{}
    \newState{2}{$2$}{right of=1}{}
    \newState{3}{$3$}{right of=2}{accepting} 

    \newTransition{0}{0}{a}{loop above}
    \newTransition{0}{0}{b}{loop below}
    \newTransition{0}{1}{a}{}
    \newTransition{1}{2}{b}{}
    \newTransition{2}{3}{b}{}
  \end{tikzpicture}
  \label{fig:transition diagram}
  \caption{Transition Diagram, accepting the pattern  $(a | b)* abb$}
  \end{figure}
\end{example}

The following example shows how the transition table would look like for the same regular expression.

\begin{example}[RegExp to Transition Table] \label{regexp2tt}
\cite{Aho2006}\\
Given the regular expression from \cref{regexp2td} it can be converted into the following transition table: \\
  \begin{figure}[h!]
  \centering
  \begin{tabular}{| c | c c c |}
    \hline
    \hline
    State & a & b & $\epsilon$\\
    \hline
    0 & $\{0, 1\}$ & $\{0\}$ & $\emptyset$ \\
    1 & $\emptyset$ & $\{2\}$ & $\emptyset$ \\
    2 & $\emptyset$ & $\{3\}$ & $\emptyset$ \\
    3 & $\emptyset$ & $\emptyset$ & $\emptyset$ \\
    \hline
  \end{tabular}
  \label{fig:transition table}
  \caption{Transition Table representation of regular expression in \cref{regexp2td}}
  \end{figure}
\end{example}
Transition tables has the advantage that they have an quick lookup time. But instead it will take allot of data space, when the alphabet is large. Most states do not have any moves on most of the input symbols. \cite{Aho2006}
\subsubsection{Deterministic Finite Automata}
DFA is a special case of an NFA where,
\begin{enumerate}
  \item there are no moves on input $\epsilon$ and
  \item for each state $s$ and input symbol $a$, there is exactly one edge out
        of $s$ labelled with $a$.
\end{enumerate}
While NFA is an abstract representation of an algorithm to recognise the string of a language, the DFA is a simple concrete algorithm for recognising strings. Every regular expression can be converted in to a NFA and every NFA can be converted in to a DFA. \cite{Aho2006} It is the DFA that is implemented and used when building lexical analysers. 
\begin{example}[DFA representation of RegExp] \label{regexp2dfa}
\cite{Aho2006}\\
A DFA representation of a regular expression shown in the following figure.
\begin{figure}[!h]
  \centering
  \begin{tikzpicture}[
    % Default arrow tip
    ->,>=stealth',shorten >=1pt,auto,
    % Default node distance
    node distance=2cm,
    % Edge stroke thickness: semithick, thick, thin
    semithick
    ]

    \newState{0}{$0$}{initial}{}
    \newState{1}{$1$}{right of=0}{}
    \newState{2}{$2$}{right of=1}{}
    \newState{3}{$3$}{right of=2}{accepting} 

    \newTransition{0}{0}{b}{loop above}
    \newTransition{0}{1}{a}{}
    \newTransition{1}{1}{a}{loop below}
    \newTransition{1}{2}{b}{}
    \newTransition{2}{3}{b}{}
    \newTransition{2}{1}{a}{bend left}
    \newTransition{3}{2}{a}{bend left}
    \newTransition{3}{0}{b}{bend right}
  \end{tikzpicture}
  \label{fig:dfa}
  \caption{DFA, accepting regular expression in \cref{regexp2td}}
\end{figure}
\end{example}

 
