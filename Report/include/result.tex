%\begin{filecontents*}{time.csv}
%characters*1000, time in microsecs
%n      alex   upd
%1000   210    150
%10000  1901   251
%20000  3910   329
%30000  5303   361
%40000  7079   361
%50000  8933   367
%60000  12140  460
%70000  14860  469
%80000  16850  523
%90000  17170  424
%100000 20920  554
%110000 24960  486
%120000 26430  503
%130000 28420  649
%140000 37890  575
%150000 33790  570
%160000 36850  624
%170000 39860  468
%180000 42570  496
%190000 42410  513
%\end{filecontents*}

\begin{filecontents*}{spacef.csv}
n                        fn
1                        1
10                       29
100                      580
1000                     8987
10000                    123631
100000                   1568946
1000000                  18951445
10000000                 223222809
100000000                2565782300
1000000000               28926258207
10000000000              322820130851
100000000000             3562561046566
1000000000000            38900488372265
10000000000000           422407813955629
100000000000000          4559262511644720
1000000000000000         48874100093157427
10000000000000000        521985601490518071
100000000000000000       5555884811924144186
1000000000000000000      58847078495393153085
10000000000000000000     621553255926290448449
\end{filecontents*}

\begin{filecontents*}{time.csv}
%characters*1000, time in microsecs
n       alex   upd  inc
1000    137    101  8492
10000   1372   174  202100
20000   2794   227  434100
30000   4103   236  498900
40000   5511   243  780100
50000   6935   228  935500
60000   8368   286  1000000
70000   9870   320  1452000
80000   11560  297  1479000
90000   13120  255  2105000
100000  14910  345  2086000
110000  16600  332  2037000
120000  18510  344  2478000
130000  20410  369  2578000
140000  22230  350  2617000
150000  24210  366  2668000
\end{filecontents*}

\begin{filecontents*}{space.csv}
n       size
100     11
200     21
400     40
800     77
1600    259
3200    387
6400    643
12800   1283
25600   2436
51200   4870
102400  9737
204800  19346
409600  38688
819200  77244
1638400 154486
\end{filecontents*}

\chapter{Result}
The incremental lexer has three requirements, it should be
robust, efficient and precise. Robustness means that the lexer does not crash
when it encounter an error in the syntax. That is, if a string would yield an
error when lexed from the starting state the lexer does not return that error but
instead stores the error and lexes the rest of the possible input states since
the current string might not be at the start of the text. The implementation
this report propose is robust since it stores errors in the data structure
rather then returning an error.

For it to be efficient the feedback to the user must be instant, or more
formally the combination of two strings should be handled in $\Theta(log(n))$ time.

Finally to be precise the lexer must give a correct result. This chapter is
describing how these requirements are tested and what the results are.

In the sections below, any mention of a sequential lexer refers to a lexer
generated by Alex using the same Alex file as was used when creating the
incremental lexer \cite{alex}. The reason why Alex was used was because the DFA
generated by Alex was used in the incremental lexer, thus ensuring that only the
lexical routines differs.

\section{Preciseness}
For an incremental lexer to work, the lexer must be able to do lexical analysis
of any part of a text and be able to combine two partial texts. If the lexical
analysis of one partial text does not result in any legal tokens it must be able
to be combined with other partial texts that makes it legal tokens. The lexical
analysis of a text might not always result in the same tokens that the
combination of the text with another text would give.

To test these cases a test was constructed which did a lexical analysis on two
partial texts using the incremental lexer and then combining the results into
one text. The result of the combination should be the same as the lexical
analysis of the entire text using the incremental lexer and the result using a
sequential lexer.

It is not enough to test if the combination of two partial texts yields the
same sequence of tokens as the text. To test that the result of the incremental
lexer was the correct sequence of tokens, it was compared to what a sequential 
lexer generated. This comparison was an equality test that compared token for
token that they were the same kind of token and had the same lexeme.

\cref{fig:CheckEquility} shows the test for equality:
\begin{figure}[h!]
  \centering
  \lstinputlisting[language=c]{examples/CorrectEquility.hs}
  notEqual function is a function which pattern-match on the two different
  tokens and returns true if they are not of the same type.
  \caption{Code for testing tokens from IncLex is equal to tokens from Alex. 
  \label{fig:CheckEquility}}
\end{figure}

Tests were performed on different files that were cut in different places when
the update was tested. In all the tests the incremental lexer produced the same
tokens as the sequential lexer. When these tests were done no text that would
produce a lexical error was used. Some partial texts did produce lexical errors
but the texts passed through the sequential lexer and compared to the result of
the incremental lexer did not produce lexical errors.

%\section{Efficiency}
\section{Performance}
All tests, where time performance was measured, were done with the help of
Criterion, a Haskell library. Criterion has tools to ensure that the functions
being tested is evaluated to normal form. Criterion runs the tests 100 times
with a warm up run by default. The warm up run makes sure that all inputs to the
functions being tested are evaluated before the actual testing begins, this
ensures that nothing but the function being tested is measured \cite{criterion}.

To make sure that the time performance tests were not skewed under a certain
system they were tested on different hardware and operating systems. The results
were similiar on all the systems tested. The results presented below were done
on an intel i5 quad core at 2900MHz with 8GB memory under the linux Red Hat
operating system.

To measure the performance of the incremental step two fingertrees were created,
each representing one half of a text. By creating the two fingertrees the
transition map for the code in those trees are created as well. The benchmarking
was then done on the combination of the two trees. The results of the incremental
lexer benchmarking sugged a running time of $\Theta(log(n))$. To get a reference
point the same text was lexed using a sequential lexer. The benchmarks can be
found in \cref{fig:IncSeqTime} and \cref{fig:IncTime}. More details on the
performance benchmarks can be found in \cref{preformanceAppendix}.

%Tester för nybyggning av träd?
\begin{figure}[!h]
%\begin{center}
\begin{tikzpicture}
    \begin{axis}[
    width=0.7\textwidth,
    height=0.4\textwidth,
    ymajorgrids,
    xmajorgrids,
    title = {Incremental lexer},
    scaled y ticks=real:1,
    scaled x ticks=real:1e3,
    ymin=0,
    xmin=0,
%    x tick label style={/pgf/number format/1000 sep=},
    ytick scale label code/.code={},
    xtick scale label code/.code={},
    ylabel={$\mu s$},
    xlabel={$*1000$ characters},
    legend pos=outer north east
    ]
        \addplot table[x=n,y=upd] {time.csv};\addlegendentry{Incremental update}
    \end{axis}
\end{tikzpicture}
%\end{center}
\caption{Benchmarking times of an incremental update\label{fig:IncTime}}
\end{figure}

\begin{figure}[!h]
%\begin{center}
\begin{tikzpicture}
    \begin{axis}[
    width=0.7\textwidth,
    height=0.4\textwidth,
    ymajorgrids,
    xmajorgrids,
    title = {Update compared to sequential},
    scaled y ticks=real:1e3,
    scaled x ticks=real:1e3,
    ymin=0,
    xmin=0,
%    x tick label style={/pgf/number format/1000 sep=},
    ytick scale label code/.code={},
    xtick scale label code/.code={},
    ylabel={$ms$},
    xlabel={$*1000$ characters},
    legend pos=outer north east
    ]
        \addplot table[x=n,y=upd] {time.csv};\addlegendentry{Incremental update}
        \addplot table[x=n,y=alex] {time.csv};\addlegendentry{Sequential lexing}
    \end{axis}
\end{tikzpicture}
%\end{center}
\caption{Comparison between an incremental update and sequential lexer\label{fig:IncSeqTime}}
\end{figure}

The running time when constructing the tree was not as fast as either the update
or the sequential lexer. The tests for the running time, when constructing a new
tree, sugged $\Theta n\log(n)$, this was expected since there are $\log(n)$
updates for every character. The result can be found in \cref{fig:IncNewTime}.

\begin{figure}[!h]
%\begin{center}
\begin{tikzpicture}
    \begin{axis}[
    width=0.7\textwidth,
    height=0.4\textwidth,
    ymajorgrids,
    xmajorgrids,
    title = {Comparison},
    scaled y ticks=real:1e3,
    scaled x ticks=real:1e3,
    ymin=0,
    xmin=0,
%    x tick label style={/pgf/number format/1000 sep=},
    ytick scale label code/.code={},
    xtick scale label code/.code={},
    ylabel={$ms$},
    xlabel={$*1000$ characters},
    legend pos=outer north east
    ]
        \addplot table[x=n,y=inc] {time.csv};\addlegendentry{Incremental lexing}
        \addplot table[x=n,y=alex] {time.csv};\addlegendentry{Sequential lexing}
    \end{axis}
\end{tikzpicture}
%\end{center}
\caption{Comparison between the sequential lexer and the incremental lexer when
         lexing an entire file\label{fig:IncNewTime}}
\end{figure}

%Since the incremental lexer uses a tree structure there will be an increase in
%data-space used compared to a sequential lexer. Since the root of every partial
%tree stores the lexed tokens for that tree, every level of the tree will store
%approximately the size of the complete tokens for the entire text. A lexer that
%uses a DFA with $m$ states will produce token data structure that grows with
%$\Theta(mn)$ since each in state will have the tokens for that state. The depth
%of the tree is $\log(n)$, this suggest a space complexity of
%$\Theta(mn\log(n))$.
The space a fingertree takes is dependent on the size of the measurement of the
tree. In the case of the incremental lexer the measurement of the tree is the
transition map. To test how much space the transition map takes a DFA for an
early Java version that has 90 states was used. The transition map was
serialized and stored to the disc using the Haskell library $Data.Binary$. The
test suggested that the size of the transition map grows linearly with the size
of text being lexed, the results can be found in \cref{fig:IncSpace}. Because of
how the transition map is constructed it will also grow linearly with the number
of states in the DFA. The test shows that the transition map has space
complexity $\Theta(mn)$.

\begin{figure}[!h]
%\begin{center}
\begin{tikzpicture}
    \begin{axis}[
    width=0.7\textwidth,
    height=0.4\textwidth,
    ymajorgrids,
    xmajorgrids,
    title = {Space for transition map},
    ymode = log,
    xmode = log,
%    scaled y ticks=real:1,
%    scaled x ticks=real:1,
    x tick label style={/pgf/number format/1000 sep=},
%    ytick scale label code/.code={Bytes},
%    xtick scale label code/.code={Characters},
    ylabel={KB},
    xlabel={Characters},
    legend pos=outer north east
    ]
        \addplot table[x=n,y=size] {space.csv};\addlegendentry{Incremental lexer}
    \end{axis}
\end{tikzpicture}
%\end{center}
\caption{Space usage of the transition map using a DFA with 90 states\label{fig:IncSpace}}
\end{figure}

To measure the space of an entire tree takes each level must be regarded. As shown
in \cref{fig:fingertree} the n:th level of a fingertree has two $2-3~trees$ of
depth n with leaves in them. The root level will therefore have a measure for
all leaves stored, that is if the measure takes $\Theta(f(n))$ space, the
measure in the root will take that much space. For the second level two
$2-3~trees$ of depth 1 has been removed, so the measure will be $\Theta(f(n-2*2))$
in the worst case. For the third level two more $2-3~trees$ have been removed and
in general on the x:th level the measure will take:
\begin{center}$\Theta(f(n-2*\sum\limits_{y=1}^x2^y))$\end{center}
Since the measure from all the levels in
the tree are stored, the total amount of data the measures takes is a sum over
all the levels, the resulting approximation can be seen in \cref{fig:MeaChar}.
For the entire equation see \cref{chap:spacecomp}.

\begin{figure}[!h]
\begin{center}
$\sum\limits_{x=0}^{\log (n-1)}(n- 2 \cdot \sum\limits_{y=1}^x2^y) =
(n+4)\log(n-1) - 7n + 16 \Rightarrow \Theta(n\log n)$
\end{center}
\caption{The number of characters being measured in a tree with n characters\label{fig:MeaChar}}
\end{figure}

Because of time limitations the size of the fingertrees were never tested. If
the approximation of the space needed for a fingertree is correct the space
complexity for the trees generated by this lexer will be $\Theta(mn\log n)$.

%\begin{figure}[!h]
%\begin{center}
%\begin{tikzpicture}
%    \begin{axis}[
%    width=0.7\textwidth,
%    height=0.4\textwidth,
%    ymajorgrids,
%    xmajorgrids,
%    title = {Space for transition map},
%    ymode = log,
%    xmode = log,
%    scaled y ticks=real:1,
%    scaled x ticks=real:1,
%    x tick label style={/pgf/number format/1000 sep=},
%    ytick scale label code/.code={Bytes},
%    xtick scale label code/.code={Characters},
%    ylabel={KB},
%    xlabel={Characters},
%    legend pos=outer north east
%    ]
%        \addplot table[x=n,y=fn] {spacef.csv};\addlegendentry{Incremental lexer}
%    \end{axis}
%\end{tikzpicture}
%\end{center}
%\caption{$y=\sum\limits_{x=0}^{log(n-1)}n-\sum\limits_{y=0}^x2^y$\label{fig:SpaceFun}}
%\end{figure}
