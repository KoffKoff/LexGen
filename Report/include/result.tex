\chapter{Result}
#Robustness, har vi egentligen i datastrukturen, det enda man kan nämna är väl att hela transition mappen sparas?

#vissa grejer kanske ska flyttas till incremental lexer delen.

The incremental lexer has as mentioned before three requirements, it should be
Robust, Efficient and Precise. Robustness means that the lexer doesn't crash
when it encounter an error in the syntax. That is, if a string would yield an
error when lexed from the starting state the lexer doesn't return that error but
instead stores the error and lexes the rest of the possible input states since
the current string might not be at the start of the code. For it to be efficient
the feedback to the user must be instant, or more formaly the combination of two
string should be handled in $O(log(n))$ time. Finally to be precise the lexer
must give a correct result. This chapter will talk about how these requirements
are tested and what results the from the tests were.

\section{Robustness}

\section{Preciseness}
For an incremental lexer to work, the lexer must be able to do lexical analysis
of any substring of a code. That is, come to a correct result for that substring
for every possible instate. It must also be able to merge any two substrings
neighboring in a code and the result of this merge must be the same as lexing
the two substrings as one substring.

One would think that haskells quickcheck would be a good way to generate in-data
for the lexer. Since quickcheck is built to generate good input for testing a
function for any arguments \cite{QuickCheck}. But the problem is not to test any
string representation, it is instead to test valid code segments and any
substring of this code segments. Also invalid pieces of code, to see that tring the
lexer informs the user for syntactical errors in these codes. To write a input
generator in quickcheck which would generate full code with all of it
components and all the different properties would be have to high cost in
develop time for the outcome. It would be more time efficient to test the lexer
on several different code files. There for the testing of the incremental lexer
has not been done with the help of quickcheck.

To test if the lexer is as close as possible to the result done by the compiler
the resulting token sequence should be the same sequence given from Alex, an
open-source lexer written in Haskell, when lexing the same code-string.
To control this the separate tokens in the resulting sequences are compared for
equality. 
The code in \cref{fig:CheckEquility} shows the test for equality:

\begin{figure}[h!]
  \centering
  \lstinputlisting[language=c]{examples/CorrectEquility.hs}
  notEqual function is a function which pattern-match on the two different
  tokens and returns true if they are not of the same type.
  \caption{Code for testing tokens from IncLex is equal to tokens from Alex. 
  \label{fig:CheckEquility}}
\end{figure} 

\subsection{Check Splits}

\subsection{Check Merges}

%\section{Efficiency}
\section{Performance}
To measure the perfomance of the incremental step we created the fingertree for
two pieces of code. By creating the two fingertrees the transition map for the
code in those trees are created aswell. The benchmarking was then done on the
combining step of these two trees and compared to the the time a traditional
sequential lexer would take for the total length of the code. For the
incremental testing we got running times which are $O(log(n))$.

#Lägga till nåt om minnes utrymmet som krävs.

#Bättre förklaring till graferna.

#Tester för nybyggning av träd?

\begin{filecontents*}{data.csv}
n     alex   upd
10    210    150
100   1901   251
200   3910   329
300   5303   361
400   7079   361
500   8933   367
600   12140  460
700   14860  469
800   16850  523
900   17170  424
1000  20920  554
1100  24960  486
1200  26430  503
1300  28420  649
1400  37890  575
1500  33790  570
1600  36850  624
1700  39860  468
1800  42570  496
1900  42410  513
\end{filecontents*}
\begin{tikzpicture}
    \begin{axis}[
    width=0.9\textwidth,
    height=0.4\textwidth,
    ymajorgrids,
    title = {benchmarking},
    x tick label style={/pgf/number format/1000 sep=},
    ytick scale label code/.code={*10ms},
    legend pos=outer north east
    ]
        \addplot table[x=n,y=upd] {data.csv};\addlegendentry{upd}
        \addplot table[x=n,y=alex] {data.csv};\addlegendentry{alex}
    \end{axis}
\end{tikzpicture}\\
\begin{tikzpicture}
    \begin{axis}[
    width=0.9\textwidth,
    height=0.4\textwidth,
    ymajorgrids,
    title = {benchmarking2},
    x tick label style={/pgf/number format/1000 sep=},
    ytick scale label code/.code={microsec},
    legend pos=outer north east
    ]
%        \addplot table[x=n,y=alex] {data.csv};\addlegendentry{alex}
        \addplot table[x=n,y=upd] {data.csv};\addlegendentry{upd}
    \end{axis}
\end{tikzpicture}
