\chapter{Implementation}
Here we should talk about bnfc and
alex. What we use from the differnet programs. How this is usefull
is it becouse of lazynes or are the existing solutions good??

\section{Alex}
Alex is a tool for generating lexical analysers built in Haskell, given a description of the language
in form of regular expressions. The result will be Haskell 98 compatible and can easly be used with the
parser Happy, a parser generator for Haskell.
\subsection{The DFA design}

\section{Monoid}
In abstract algebra a monoid is a set, $S$, and a binary operation $\bullet$ which furfills the following
three properties:
\begin{description}
\item[Closure] $\forall a,b \in S: a \bullet b \in S$
\item[Associativity] $\forall a,b,c \in S: (a \bullet b) \bullet c = a \bullet (b \bullet c)$
\item[Identity element] $\exists e \in S: \forall a \in S: e \bullet a = a \bullet e = a$
\end{description}

\subsection{The Basecase}
\subsection{The Conquer Step}

\section{Fingertree}
The incremental lexer uses a tree structure to save already lexed content. This tree is of form Fingertree.
What that is and the basics of it is described in this section.

\subsection{Fundemental Conscepts}
Before describing the functionality, lets take a look on which buildingblocks the fingertrees uses.
\paragraph{First,}
the fingertree uses monoids which has been described earlier in this chapter.
\paragraph{Second,} 
the fingertree uses Right and Left Reductions. This a function which collapses a structure of $f$ $a$ into
a single value of type $a$. The basecase for when the tree is empty is replaced with a constant value, such as
$\emptyset$. intermediate results are combined using a binary operation, like the monoids $\bullet$.
Reduction with a monoid always return the same value, independent of the argument nesting. But for a reduction with 
an arbitraty constant and binary operation there must be a specified nesting rule. 
If combining operation are only nested to the right, or to the
left, the obtained result will be a skewed reductions, which can be singled out as a type class.
class Reduce f where\\
reducer :: (a → b → b) → (f a → b → b)\\
reducel :: (b → a → b) → (b → f a → b)\\
\cite{fingertree}

\section{Sequences}
A sequence in Haskell is a form of sophisticated list. That is a list with better performance than the basic [] list notation. Where a list in Haskell has $\Theta(n)$ for finding, inserting or deleting elements, that is in a list there is only known current element and the rest of the list. Which will result in for example finding the last element of a list, the computer must look at every element until the empty list has been found as the rest of the list. Where in a sequence the last element can be obtained in $\Theta(1)$ time. Adding a element anywhere in the sequence can be done in worst case, $\Theta(log n)$ \cite{fingertree}. 

Since this project is about creating as real-time lexing tool, performance is very important. String in Haskell are just a list of characters, [Char], and therefor has $\Theta(n)$ in time cost. Lexing is working with strings in a high frequency and there for there is a idea of instead define a string as a sequence of characters instead of a list of character. 

\section{Transition Map}
\subsection{Array Format}
\subsection{Function Composition Format}
