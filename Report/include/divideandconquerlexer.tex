\chapter{Divide-and-Conquer Lexer}
An incremental lexer works by dividing the sequence, to be lexicaly analysed,
into it's smallest part and analyse them; and then combining them. In the base
case the lexical analysis is done on a single character. The conquer step is
then to combine the smaller tokens into as large tokens as possible. The end
result should be a sequence of token that represent the code. How this is done
will be described below. \#Some ref to divide and conquer?


\section{The Structure} %Better title
For the lexer to be able to represent every possible substring of the code in the same datastructure. There need to be a generic representation for tokens and subtokens. A subtoken is a representing of a lexeme for that subtoken and a list of accepting tokens for that lexeme. The final tokens is a sequence of subtokens the output state for this sequence and an suffix, this suffix can be empty or conssist of an alternetiv ending for the sequence of tokens. What this is and how it works will be described more in detail in \cref{section:Suffix}.
In \cref{fig:DataStruct} is a code representation of the datastructure

\begin{figure}[h!]
  \centering
  \lstinputlisting[language=c]{examples/Datastruct.hs}
  \caption{Datastructure for tokens and lexems. 
  \label{fig:DataStruct}}
\end{figure} 

\section{The Power of Suffix
\label{section:Suffix}}

\section{Lexing in the middle attack} %better title
When the code is divided the lexer doesn't know if the string (or character) it
lexes is the first, last or is somewhere in the middle of a token. Instead of
checking what type of token the string will be (if it were to begin from the
starting state) it saves all the possible state transitions for that string.

In the examples that follow below state 0 is considered the starting state and
state $1-6$ are considered accepting.
\begin{example}[Transition map for a token]\label{transMap}
A hypothetical transition map for the char 'i'.
\begin{center}$\begin{array}{cc}
\multicolumn{2}{c}{'i'}\\
in & out\\
0 & 1\\
1 & 1\\
8 & 7\\
\end{array}$\\
\end{center}
\end{example}
In the base case the lexer will map all the transitions for all individual
characters in the code and construct partial tokens of them. The conquer step
will then combine two of these at a time by checking which possible outgoing
states from the first token can be matched with incoming states from the second
token. If there are such pairs of outgoing states with incomming states, then a
new partial token is created.
\begin{example}[Combining two tokens]\label{combTok}
'if' can be an ident (state 1) or part of 'else if' (state 5).
\begin{center}$\begin{array}{cc}
\multicolumn{2}{c}{'i'}\\
in & out\\
\textcolor{brown}{0} & \textcolor{brown}{1}\\
1 & 1\\
\textcolor{blue}{8} & \textcolor{blue}{7}\\
\end{array}
`combineToken`
\begin{array}{cc}\multicolumn{2}{c}{'f'}\\
in & out\\
0 & 1\\
\textcolor{brown}{1} & \textcolor{brown}{1}\\
\textcolor{blue}{7} & \textcolor{blue}{5}\\
\end{array}
=
\begin{array}{cc}\multicolumn{2}{c}{'if'}\\
in & out\\
\textcolor{brown}{0} & \textcolor{brown}{1}\\
\textcolor{blue}{8} & \textcolor{blue}{5}\\
\end{array}$\\
\end{center}
\end{example}
If there are no pairs of outgoing states which match the incomming states the
lexer will try to combine the first token with as much of the second token as
possible. In this case there will be a remainder of the second token, The lexer
can now be sure that the begining of the remainder is the begining of a token
and that the merged part is the end of the token before.
Since the lexer knows the remainder is the begining of a token it strips all
transitions but the one that has incomming state as starting state. Since the
start token is the end of a Token it strips all but the transitions ending in an
accepting state.
\begin{example}[Combining a token a part of the second token]\label{combSplit}
'ie' ends in the accepting state for ident (1) and '\_' starts in the
starting state.
\begin{center}
$\begin{array}{cc}\multicolumn{2}{c}{'e\_'}\\
in & out\\
\textcolor{brown}{10} & \textcolor{brown}{8}\\
\end{array}
=
\begin{array}{cc}\multicolumn{2}{c}{'e'}\\
in & out\\
0 & 11\\
\textcolor{blue}{1} & \textcolor{blue}{1}\\
6 & 1\\
\textcolor{brown}{10} & \textcolor{brown}{9}\\
\end{array}
`combineToken`
\begin{array}{cc}\multicolumn{2}{c}{'\_'}\\
in & out\\
0 & 2\\
2 & 2\\
\textcolor{brown}{9} & \textcolor{brown}{8}\\
\end{array}
$\\
$\begin{array}{cc}
\multicolumn{2}{c}{'i'}\\
in & out\\
\textcolor{blue}{0} & \textcolor{blue}{1}\\
\textcolor{blue}{1} & \textcolor{blue}{1}\\
8 & 7\\
\end{array}
`combineToken`
\begin{array}{cc}\multicolumn{2}{c}{'e\_'}\\
in & out\\
10 & 8\\
\end{array}
=
\begin{array}{cc}\multicolumn{2}{c}{'ie'}\\
in & out\\
\textcolor{blue}{0} & \textcolor{blue}{1}\\
\textcolor{blue}{1} & \textcolor{blue}{1}\\
\end{array} ++ 
\begin{array}{cc}\multicolumn{2}{c}{'\_'}\\
in & out\\
0 & 2\\
\end{array}$\\
\end{center}
\end{example}
\# Perhaps remove this part\\
However the remainder may not have the start state as a possible incomming state.
In this case the lexer tries to find the largest possible token (that has the
starting state as incomming state) and tries to construct a token of the rest of
the remainder, repeating this procedure until the entire remainder has been
split into acceptable tokens. All the tokens accept the one that is on the very
end of the sequence will have all but their accepting states stripped. This case
does occur quite frequently since most languages has comments and strings which
can contain anything.
\begin{example}[Handling the remainder]\label{remToken}
'\_' starts in the starting states and ends in an accepting state and 'e' starts
in the starting state, it doesn't have to end in an accepting state.
\begin{center}
$\begin{array}{cc}\multicolumn{2}{c}{'\_i'}\\
in & out\\
\textcolor{brown}{9} & \textcolor{brown}{7}\\
\end{array}
=
\begin{array}{cc}\multicolumn{2}{c}{'\_'}\\
in & out\\
0 & 2\\
2 & 2\\
\textcolor{brown}{9} & \textcolor{brown}{8}\\
\end{array}
`combineToken`
\begin{array}{cc}
\multicolumn{2}{c}{'i'}\\
in & out\\
0 & 1\\
1 & 1\\
\textcolor{brown}{8} & \textcolor{brown}{7}\\
\end{array}$\\
$checkRemainder \left(\begin{array}{cc}\multicolumn{2}{c}{'\_i'}\\
in & out\\
9 & 7\\
\end{array} \right)
=
\begin{array}{cc}\multicolumn{2}{c}{'\_'}\\
in & out\\
0 & 2\\
\end{array} ++
\begin{array}{cc}\multicolumn{2}{c}{'i'}\\
in & out\\
0 & 1\\
\end{array}$\\
\end{center}
\end{example}
When all partial tokens has been combined in this way the resulting sequence of
tokens represents the the code the lexer was run on.


\subsection{Pitfalls}
The above rules will work for very simple languages. When comments are
introduced you will get the problem that the whole code can be one long partial
comment token. To remedy this you can add two rules:
\begin{itemize}
\item Every time you combine two tokens you only do so if the combination has a
transition from the starting state.
\item If two tokens can be combined completly, check if the next token can be
combined aswell.
\end{itemize}
This ensures that every token starts in the starting state and that each token
is as long as it can be.

This also has some problems though. When keywords like ``else if'' are
introduced the lexer will start to lex like in \cref{elseif}. To solve this the
lexer checks when two tokens are completely uncombinable if the first of these
have an accepting state as outgoing state. If the token don't have an accepting
out state, the lexer tries to break up the token until it does. The exception to
this rule is single characters which are permitted to not have no accepting out
states.
\begin{example}[else if lexing]\label{elseif}
Somewhere in the middle of the code ``... 1 else 0 ...''
\begin{center}
\begin{tabular}{ll}
String & Type\\
1 & $Number$\\
\_ & $Space$\\
else\_ & $Nothing$\\
0 & $Number$\\
\end{tabular}
\end{center}
\end{example}
\subsection{The rules}
To sum up the rules that lexer needs to follow are the following:
\begin{itemize}
\item If two tokens can be combined, combine the result with the next token.
\item All tokens must start in the starting state (exception are single
character tokens).
\item If two tokens can't be completly combined, combine the first token with as
much as possible of the second token and check that the combination ends in an
accepting state.
\end{itemize}
\newpage
\begin{example}[Devide and Append]
The lexer will always try to build as lage tokens as possible. When it realizes that this cant be done it has to backup and try to combine the parts in a different way. This example will show how this is done in theory. 

The code segment for this example is: 
\begin{center}
"else return".
\end{center}
The tree in \cref{fig1:elseif} shows the first step of the token combine rutine. Clearly this returns a nonexsisting token. 
\begin{figure}[h!]
  \centering
  \begin{tikzpicture}[
    error/.style={rectangle, draw=none, rounded corners=1mm, fill=black!20!red, drop shadow,
        text centered, anchor=north, text=white},
    fact/.style={rectangle, draw=none, rounded corners=1mm, fill=black!60!green, drop shadow,
        text centered, anchor=north, text=white},
    state/.style={rectangle, draw=none, rounded corners=1mm, fill=blue, drop shadow,
        text centered, anchor=north, text=white},
    leaf/.style={rectangle, draw=none, rounded corners=1mm, fill=blue, drop shadow,
        text centered, anchor=north, text=white},
    level distance=0.5cm, growth parent anchor=south
    ]
    \node (State00) [error] {NoToken} [->]
        child{ [sibling distance=9cm]
            node (State01) [state] {"else return"}
            child{
                node (Fact02) [fact] {PossibleToken(ElseIf)}
                child{ [sibling distance=4cm]
                    node (State02) [state] {"else "}
                    child{
                        node (Fact03) [fact] {Token(Else)}
                        child{
                            node (State03) [leaf] {"else"}
                        }
                    }
                    child{
                        node (Fact04) [fact] {Token(WhiteSpace)}
                        child{ [sibling distance=1.2cm]
                            node (State04) [leaf] {" "}
                        }
                    }
                }
            }
            child{ [sibling distance=4cm]
                node (Fact05) [fact] {Token(Return)}
                child{
                    node (State05) [leaf] {"return"}
                }
            }
        }
    ;
  \end{tikzpicture}
  \caption{Lexer thinks "else " is an "else if" pattern. 
  \label{fig1:elseif}}
\end{figure}
From here when the lexer has found that there are no tokens for this lexeme it will try to split the left child token.
\begin{center}
    split("else ") => ["else"," "]
\end{center} 
Now the lexer has a pair of two lexems that represent valid tokens. The lexer knows that combinding these two lexems in the pair returns in a NoToken result. So The only thing to do is to try to combine the right token in the pair with the right child token and let the token to the left in the pair stand alone. 
\begin{figure}[!h]
  \centering
  \begin{tikzpicture}[
    error/.style={rectangle, draw=none, rounded corners=1mm, fill=black!20!red, drop shadow,
        text centered, anchor=north, text=white},
    fact/.style={rectangle, draw=none, rounded corners=1mm, fill=black!60!green, drop shadow,
        text centered, anchor=north, text=white},
    state/.style={rectangle, draw=none, rounded corners=1mm, fill=blue, drop shadow,
        text centered, anchor=north, text=white},
    leaf/.style={rectangle, draw=none, rounded corners=1mm, fill=blue, drop shadow,
        text centered, anchor=north, text=white},
    level distance=0.5cm, growth parent anchor=south
    ]
    \node (State00) [error] {NoToken} [->]
        child{ [sibling distance=4cm]
            node (State01) [state] {" return"}
            child{ [sibling distance=4cm]
                node (State02) [fact] {Token(WhiteSpace)}
                child{
                    node (Fact02) [leaf] {" "}
                }
            }
            child{ [sibling distance=4cm]
                node (Fact03) [fact] {Token(Return)}
                child{
                    node (State03) [leaf] {"return"}
                }
            }
        }
    ;
  \end{tikzpicture}
  \caption{Lexer tries to combine an white space with a return statement
  \label{fig4:elseif}}
\end{figure}
This also return a NoToken. So the same thing will be done again. The lexer tries to split the left child before NoToken was given. In this case the whitespace. 
\begin{center}
split(" ") => []
\end{center}
But becouse the whitespace is of the lowest form and is not build up by smaller tokens the resulting list from the split function will be empty. Now the lexer knows that this token must be by it self. The "return" is the last lexeme in this example code so the lexer can't combine it futher. Thus the lexer has found the resulting sequence of tokens:
\begin{center}
    [(Token(Else), "else"), (Token(WhiteSpace)," "), (Token(Return), "return")]
\end{center} 
\end{example}
\section{Lexical Errors}
Since the lexer has to be able to handle any kind of possible not \"complete\"
tokens, error handling can be done in different ways. One approach is to simply
return as many tokens as possible from the code and where there might be lexical
errors the lexer returns the error in as small parts as possible.
\begin{example}[A lexer that only lexes letters] When the lexer encounters the
string \"what @ day\" it would return:
\begin{center}
\begin{tabular}{ll}
String & Type\\
What & $Word$\\
'\_' & $Space$\\
'@' & $No\_Token$\\
'\_' & $Space$\\
day & $Word$\\
\end{tabular}
\end{center}
\end{example}
% Make some sort of conclusion
\section{Considered Data-Structures}
\# We should here also talk about some datastructers that is needed for a
incremental lexer to work.
\subsection{Code Sturcture}
\# We should talk about how to represent the code and result as a tree 
structure to easy know where changes has been added in the code. and only 
update the result for the code affected by the changes. 
\subsection{Transistion Structures}
\#How should our DFA or more exactly our transistions be represented to get 
maximum awesomeness in our program.

\section{Transition map}
To be able to make a divide-and-conquer lexer work you can use a transition map
for the subexpression that has currently been lexed. That is you store for each
subexpression a list of tuples which are built up of an in state, a list of
tokens and an out state. This could in haskell look something like this.
\begin{verbatim}
type transition = [(State,Tokens,State)]
\end{verbatim}
The $tokens$ type helps to think of as being a sufix, that is the first part of
the substring, this has to end in an accepting state; a list of tokens which all
are complete tokens, they start in the starting state and end in an accepting
state; and a prefix, the last part of the lexed substring, this part has
to begin in the starting state; or just a single partial token that can be
anywhere in a token.
\begin{verbatim}
data Tokens = Single String
            | Multiple String [Token] String
\end{verbatim}
Now lets see how these data types work in order to create list of tokens for a
String.
\subsection{The Base Case}
When the lexer tries to lex one character it will create the above transition
table using the DFA for the language. It will for each state in the DFA lookup
what out state the character would yield and create a Tokens type of Single.
For the character '/' part of a transition map might look like the following.
$\left[\begin{array}{ccc}
$10$&Single '/'&$10$\\
$11$&Single '/'&NoState\\
$12$&Single '/'&$10$\\
\end{array}\right]$
The reason we keep track of $NoState$ will be evident ones we show how the
conquer step work.
\subsection{Conquer Step}
When two list of tokens are combined there are two cases that can emerge. The
first being that a transition from the first list has an out state that
corresponds to an in state with a valid out state, i.e. not $NoState$, in the
second list of transitions. In this case the sufix of the first transition will
be paired with the prefix of the second and seen as a complete token.
$\left[\begin{array}{ccc}
$0$&Single '//'&$1$\\
$1$&Multiple '/' [] '/' &$2$\\
\end{array}\right]$ $+$ EN ANNAN JÃ„VLA TOKENSEKVENS\\
The second case is when the out state for the right token list is $NoState$.
This means that 
