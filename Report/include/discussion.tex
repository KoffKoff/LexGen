\chapter{Discussion}
\#Discuss discuss!!

One would think that haskells quickcheck would be a good way to generate in-data
for the lexer. Since quickcheck is built to generate good input for testing a
function for any arguments \cite{QuickCheck}. But the problem is not to test any
string representation, it is instead to test valid code segments and any
substring of this code segments. Also invalid pieces of text, to see that the
lexer informs the user of syntactical errors in these texts. To write a input
generator in quickcheck which would generate full code with all of its
components and all the different properties would have to high cost in
develop time for the outcome. It would be more time efficient to test the lexer
on several different code files. There for the testing of the incremental lexer
has not been done with the help of quickcheck.

\#possibility of using sequential lexing first time?

\#When is it advantagous with incremental lexing


\section{Pitfalls}
This section will describe techniques that were tried under the constuction of 
the incremental divide and conquer lexer but was shown to give bad results.

\subsection{Brutefore}
The first naive solution was to "bruteforce" to find the lex. This was showned
to be to resource-eating. But it describes the general idea of how the problem
could be solved. Why it was a bad solution will be described futher on in the
text. 

The above rules will work for very simple languages. When comments are
introduced you will get the problem that the whole code can be one long partial
comment token. To remedy this you can add two rules:
\begin{itemize}
\item Every time you combine two tokens you only do so if the combination has a
transition from the starting state.
\item If two tokens can be combined completly, check if the next token can be
combined aswell.
\end{itemize}
This ensures that every token starts in the starting state and that each token
is as long as it can be.

This also has some problems though. When keywords like ``else if'' are
introduced the lexer will start to lex like in \cref{elseif}. To solve this the
lexer checks when two tokens are completely uncombinable if the first of these
have an accepting state as outgoing state. If the token don't have an accepting
out state, the lexer tries to break up the token until it does. The exception to
this rule is single characters which are permitted to not have no accepting out
states.
\begin{example}[else if lexing]\label{elseif}
Somewhere in the middle of the code ``... 1 else 0 ...''
\begin{center}
\begin{tabular}{ll}
String & Type\\
1 & $Number$\\
\_ & $Space$\\
else\_ & $Nothing$\\
0 & $Number$\\
\end{tabular}
\end{center}
\end{example}

\begin{example}[Devide and Append]
The lexer will always try to build as lage tokens as possible. When it realizes that this cant be done it has to backup and try to combine the parts in a different way. This example will show how this is done in theory. 

The code segment for this example is: 
\begin{center}
"else return".
\end{center}
The tree in \cref{fig1:elseif} shows the first step of the token combine rutine. Clearly this returns a nonexsisting token. 
\begin{figure}[h!]
  \centering
  \begin{tikzpicture}[
    error/.style={rectangle, draw=none, rounded corners=1mm, fill=black!20!red, drop shadow,
        text centered, anchor=north, text=white},
    fact/.style={rectangle, draw=none, rounded corners=1mm, fill=black!60!green, drop shadow,
        text centered, anchor=north, text=white},
    state/.style={rectangle, draw=none, rounded corners=1mm, fill=blue, drop shadow,
        text centered, anchor=north, text=white},
    leaf/.style={rectangle, draw=none, rounded corners=1mm, fill=blue, drop shadow,
        text centered, anchor=north, text=white},
    level distance=0.5cm, growth parent anchor=south
    ]
    \node (State00) [error] {NoToken} [->]
        child{ [sibling distance=9cm]
            node (State01) [state] {"else return"}
            child{
                node (Fact02) [fact] {PossibleToken(ElseIf)}
                child{ [sibling distance=4cm]
                    node (State02) [state] {"else "}
                    child{
                        node (Fact03) [fact] {Token(Else)}
                        child{
                            node (State03) [leaf] {"else"}
                        }
                    }
                    child{
                        node (Fact04) [fact] {Token(WhiteSpace)}
                        child{ [sibling distance=1.2cm]
                            node (State04) [leaf] {" "}
                        }
                    }
                }
            }
            child{ [sibling distance=4cm]
                node (Fact05) [fact] {Token(Return)}
                child{
                    node (State05) [leaf] {"return"}
                }
            }
        }
    ;
  \end{tikzpicture}
  \caption{Lexer thinks "else " is an "else if" pattern. 
  \label{fig1:elseif}}
\end{figure}
From here when the lexer has found that there are no tokens for this lexeme it will try to split the left child token.
\begin{center}
    split("else ") => ["else"," "]
\end{center} 
Now the lexer has a pair of two lexems that represent valid tokens. The lexer knows that combinding these two lexems in the pair returns in a NoToken result. So The only thing to do is to try to combine the right token in the pair with the right child token and let the token to the left in the pair stand alone. 
\begin{figure}[!h]
  \centering
  \begin{tikzpicture}[
    error/.style={rectangle, draw=none, rounded corners=1mm, fill=black!20!red, drop shadow,
        text centered, anchor=north, text=white},
    fact/.style={rectangle, draw=none, rounded corners=1mm, fill=black!60!green, drop shadow,
        text centered, anchor=north, text=white},
    state/.style={rectangle, draw=none, rounded corners=1mm, fill=blue, drop shadow,
        text centered, anchor=north, text=white},
    leaf/.style={rectangle, draw=none, rounded corners=1mm, fill=blue, drop shadow,
        text centered, anchor=north, text=white},
    level distance=0.5cm, growth parent anchor=south
    ]
    \node (State00) [error] {NoToken} [->]
        child{ [sibling distance=4cm]
            node (State01) [state] {" return"}
            child{ [sibling distance=4cm]
                node (State02) [fact] {Token(WhiteSpace)}
                child{
                    node (Fact02) [leaf] {" "}
                }
            }
            child{ [sibling distance=4cm]
                node (Fact03) [fact] {Token(Return)}
                child{
                    node (State03) [leaf] {"return"}
                }
            }
        }
    ;
  \end{tikzpicture}
  \caption{Lexer tries to combine an white space with a return statement
  \label{fig4:elseif}}
\end{figure}
This also return a NoToken. So the same thing will be done again. The lexer tries to split the left child before NoToken was given. In this case the whitespace. 
\begin{center}
split(" ") => []
\end{center}
But becouse the whitespace is of the lowest form and is not build up by smaller tokens the resulting list from the split function will be empty. Now the lexer knows that this token must be by it self. The "return" is the last lexeme in this example code so the lexer can't combine it futher. Thus the lexer has found the resulting sequence of tokens:
\begin{center}
    [(Token(Else), "else"), (Token(WhiteSpace)," "), (Token(Return), "return")]
\end{center} 
\end{example}

\subsection{Dont know what to call this!}
When the code is divided the lexer doesn't know if the string (or character) it
lexes is the first, last or is somewhere in the middle of a token. Instead of
checking what type of token the string will be (if it were to begin from the
starting state) it saves all the possible state transitions for that string.

In the examples that follow below state 0 is considered the starting state and
state $1-6$ are considered accepting.
\begin{example}[Transition map for a token]\label{transMap}
A hypothetical transition map for the char 'i'.
\begin{center}$\begin{array}{cc}
\multicolumn{2}{c}{'i'}\\
in & out\\
0 & 1\\
1 & 1\\
8 & 7\\
\end{array}$\\
\end{center}
\end{example}
In the base case the lexer will map all the transitions for all individual
characters in the code and construct partial tokens of them. The conquer step
will then combine two of these at a time by checking which possible outgoing
states from the first token can be matched with incoming states from the second
token. If there are such pairs of outgoing states with incomming states, then a
new partial token is created.
\begin{example}[Combining two tokens]\label{combTok}
'if' can be an ident (state 1) or part of 'else if' (state 5).
\begin{center}$\begin{array}{cc}
\multicolumn{2}{c}{'i'}\\
in & out\\
\textcolor{brown}{0} & \textcolor{brown}{1}\\
1 & 1\\
\textcolor{blue}{8} & \textcolor{blue}{7}\\
\end{array}
`combineToken`
\begin{array}{cc}\multicolumn{2}{c}{'f'}\\
in & out\\
0 & 1\\
\textcolor{brown}{1} & \textcolor{brown}{1}\\
\textcolor{blue}{7} & \textcolor{blue}{5}\\
\end{array}
=
\begin{array}{cc}\multicolumn{2}{c}{'if'}\\
in & out\\
\textcolor{brown}{0} & \textcolor{brown}{1}\\
\textcolor{blue}{8} & \textcolor{blue}{5}\\
\end{array}$\\
\end{center}
\end{example}
If there are no pairs of outgoing states which match the incomming states the
lexer will try to combine the first token with as much of the second token as
possible. In this case there will be a remainder of the second token, The lexer
can now be sure that the begining of the remainder is the begining of a token
and that the merged part is the end of the token before.
Since the lexer knows the remainder is the begining of a token it strips all
transitions but the one that has incomming state as starting state. Since the
start token is the end of a Token it strips all but the transitions ending in an
accepting state.
\begin{example}[Combining a token a part of the second token]\label{combSplit}
'ie' ends in the accepting state for ident (1) and '\_' starts in the
starting state.
\begin{center}
$\begin{array}{cc}\multicolumn{2}{c}{'e\_'}\\
in & out\\
\textcolor{brown}{10} & \textcolor{brown}{8}\\
\end{array}
=
\begin{array}{cc}\multicolumn{2}{c}{'e'}\\
in & out\\
0 & 11\\
\textcolor{blue}{1} & \textcolor{blue}{1}\\
6 & 1\\
\textcolor{brown}{10} & \textcolor{brown}{9}\\
\end{array}
`combineToken`
\begin{array}{cc}\multicolumn{2}{c}{'\_'}\\
in & out\\
0 & 2\\
2 & 2\\
\textcolor{brown}{9} & \textcolor{brown}{8}\\
\end{array}
$\\
$\begin{array}{cc}
\multicolumn{2}{c}{'i'}\\
in & out\\
\textcolor{blue}{0} & \textcolor{blue}{1}\\
\textcolor{blue}{1} & \textcolor{blue}{1}\\
8 & 7\\
\end{array}
`combineToken`
\begin{array}{cc}\multicolumn{2}{c}{'e\_'}\\
in & out\\
10 & 8\\
\end{array}
=
\begin{array}{cc}\multicolumn{2}{c}{'ie'}\\
in & out\\
\textcolor{blue}{0} & \textcolor{blue}{1}\\
\textcolor{blue}{1} & \textcolor{blue}{1}\\
\end{array} ++ 
\begin{array}{cc}\multicolumn{2}{c}{'\_'}\\
in & out\\
0 & 2\\
\end{array}$\\
\end{center}
\end{example}
\# Perhaps remove this part\\
However the remainder may not have the start state as a possible incomming state.
In this case the lexer tries to find the largest possible token (that has the
starting state as incomming state) and tries to construct a token of the rest of
the remainder, repeating this procedure until the entire remainder has been
split into acceptable tokens. All the tokens accept the one that is on the very
end of the sequence will have all but their accepting states stripped. This case
does occur quite frequently since most languages has comments and strings which
can contain anything.
\begin{example}[Handling the remainder]\label{remToken}
'\_' starts in the starting states and ends in an accepting state and 'e' starts
in the starting state, it doesn't have to end in an accepting state.
\begin{center}
$\begin{array}{cc}\multicolumn{2}{c}{'\_i'}\\
in & out\\
\textcolor{brown}{9} & \textcolor{brown}{7}\\
\end{array}
=
\begin{array}{cc}\multicolumn{2}{c}{'\_'}\\
in & out\\
0 & 2\\
2 & 2\\
\textcolor{brown}{9} & \textcolor{brown}{8}\\
\end{array}
`combineToken`
\begin{array}{cc}
\multicolumn{2}{c}{'i'}\\
in & out\\
0 & 1\\
1 & 1\\
\textcolor{brown}{8} & \textcolor{brown}{7}\\
\end{array}$\\
$checkRemainder \left(\begin{array}{cc}\multicolumn{2}{c}{'\_i'}\\
in & out\\
9 & 7\\
\end{array} \right)
=
\begin{array}{cc}\multicolumn{2}{c}{'\_'}\\
in & out\\
0 & 2\\
\end{array} ++
\begin{array}{cc}\multicolumn{2}{c}{'i'}\\
in & out\\
0 & 1\\
\end{array}$\\
\end{center}
\end{example}
When all partial tokens has been combined in this way the resulting sequence of
tokens represents the the code the lexer was run on.

