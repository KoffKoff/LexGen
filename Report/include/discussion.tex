\chapter{Discussion}
During the course of the project there were some set backs. The first set back
was that our initial solution had bad running time, hard to understand and did
not handle longest matching correctly.

After the first solution came a solution
that was easier to understand but still had problem with the longest match. The
running time was greatly improved from the first version but was still not
faster then sequential lexers.

To solve this our last implementation which is
described in \#ENREF (tm) TILL IMPLEMENTATION\# made use of arrays and a DFA from
Alex. The longest match problems that existed in the earlier versions of the
lexer was mainly due to difficulty finding the correct solution.

\section{Used Programming Language and Data Structure}
The project is written in Haskell. One of the reasons is that similar
research and projects have been done in Haskell, for instance \cite{blog} and \cite{fingertree}.
Haskell also has the tools and the data structures used in the project. For
instance Alex was used in two parts, first the DFA generated was used and second
a lexer generated by alex was used to get a comparison of the lexing time.

There are other advantages of using Haskell as implementation language, namely
higher order functions, lazy evaluation and function composition. Functional
composition is useful in the lexical routines since the transitions are
implemented as functions and are more or less just evaluated by composing.
Lazy evaluation is used in when the lexical routines are called. The lexer does
not need to evaluate all the intermediate steps if there is more composition
that has not yet been done.
%Higher order functions can be used when constructing a full-fledged lexer generator.

The project could have been done in other languages. There are for example
lexer generators in other languages, lex, Flex and Jlex, which can be used to
create an efficient DFA. There have also been earlier articles that handle
problems similar to this project written in Java \cite{JavaIncRegExp}.

The advantage of using finger trees in an incremental lexer is that it is easy
to keep track of which tokens correspond to which part of the text, since the
tokens are in the measure of the tree. Finger trees
also has the advantage of keeping track of earlier result. When a tree is split
up the tokens that match the sub texts are already calculated. The time
complexity for combining two trees is low, O(log n), where n is the size of the
smallest tree. The lexical routines revolve around combining two lexical
results. Because of this it is advantageous to use finger trees since combination
of two finger trees are fast. The main reason to not use any other type of tree
is that another tree would not keep track of measure for sub trees. In the case
of splitting a tree the tokens would have to be recalculated.

\section{Development Stages}
The first version of the lexical routines only had the goal to get an idea of
how a divide and conquer lexer could be implemented. As a result a lot of
unnecessary information was stored and computed and some necessary information
was stored and computed more then once. The solution was to calculate
uncertain tokens until a satisfactory result was found or all possibilities was
exhausted. This meant that for each combination the worst case was $O(2^n)$.

The next step was to make sure that the information was stored in the right
places and that no unnecessary information was stored. To solve this an overhaul
of the projects data structure was made. The result is close to the structure
used in the final result. This solution still had some problem with the running
time. The main reason was that the lexical result wasn't explicitly stored in
the finger trees. That is, the functional composition was stored in the finger
trees.

The last stage of the development was to make the lexer run fast and to make
sure that fringe cases were computed correctly. The solution to this was to use
arrays in the measure of the finger trees since arrays are always explicitly
evaluated to normal form and that they have quick lookup time $O(1)$. Since the
lexical routines can take advantage of the transitions in the form of functions
that representation was used in the lexical routines and functions for
converting between the arrays and function representation was implemented.

\section{Advantages and Disadvantages}
The updating step of the lexer is fast since the only computation needed is the
combination of the last token of the first tree with the first token of the
second tree and the combination of the actual trees. If an incremental lexer is
used the finger trees should be stored instead of the raw text. If the finger
trees are not stored the finger tree would need to be recalculated each time the
file was opened.

Incremental lexers is not suited to be used in a stand alone lexer since the
lexical routine is more time consuming per character then a sequential lexer. If
a development environment that uses an incremental lexer was used, the stand
alone lexer can be omitted since the tokens are already generated, saving one
step in the compilation process.

An incremental lexer can be used in a text editor for syntax high lighting.
Insertion of a character in the text will be faster with an incremental lexer
compared to a sequential lexer since the text does not need to be reevaluated.
This means that the lexer could be run in real time without a user noticing it.
The result from an incremental lexer can be passed to an incremental parser,
giving parsing feedback to the user instead. The down side is that more data
needs to be stored with the text to have fast loading time.
